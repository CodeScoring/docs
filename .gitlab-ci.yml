stages:
  - lint

lint_markdown:
  stage: lint
  script:
    - echo "üîç Starting markdown linting..."
    - echo "Available tools:"
    - which git grep sed tr awk wget curl || echo "Some tools missing"
    - |
      if [ -n "$CI_MERGE_REQUEST_DIFF_BASE_SHA" ]; then
        BASE_REF="$CI_MERGE_REQUEST_DIFF_BASE_SHA"
      else
        echo "Fetching origin/main..."
        git fetch origin main || { echo "Failed to fetch origin/main"; exit 1; }
        BASE_REF="origin/main"
      fi

      FILES=$(git diff --name-only "$BASE_REF"...HEAD -- '*.md') || { echo "Failed to get changed files"; exit 1; }

      if [ -z "$FILES" ]; then
        echo "‚ÑπÔ∏è No .md files changed."
        exit 0
      fi

      echo "üìÑ Changed files: $FILES"
      ERROR_FOUND=false

      # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ trailing spaces
      echo "üîç Checking trailing spaces..."
      for file in $FILES; do
        if grep -n '[[:blank:]]$' "$file" 2>/dev/null; then
          echo "Trailing spaces in $file"
          ERROR_FOUND=true
        fi
      done
      [ "$ERROR_FOUND" = false ] && echo "No trailing spaces."

      # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫ (—Å —É—á–µ—Ç–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏—è Material for MkDocs)
      echo "Checking internal links..."
      for file in $FILES; do
        echo "Processing $file..."
        LINKS=$(grep -oP '\[.*?\]\(\K(?:#[^\s)]+|/[^\s)]+#[^\s)]+)' "$file" | sed 's/^\(#[^/]\+\|\/[^#]\+#\)/\1/' || true)
        if [ -n "$LINKS" ]; then
          echo "Found links: $LINKS"
          while IFS= read -r link; do
            [ -z "$link" ] && continue

            if echo "$link" | grep -q '^#'; then
              TARGET_FILE="$file"
              ANCHOR="${link#\#}"
            else
              PATH_PART=$(echo "$link" | sed 's/#.*$//; s|^/||; s|/$||')
              TARGET_FILE="docs/${PATH_PART}.md"
              ANCHOR="${link##*#}"
            fi

            if [ -f "$TARGET_FILE" ]; then
              # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —è–∫–æ—Ä—è
              HEADINGS=$(grep -E '^#{1,6} ' "$TARGET_FILE" | sed 's/^#\+ //')
              GENERATED_ANCHORS=""
              COUNT=1
              while IFS= read -r heading; do
                safe=$(echo "$heading" | tr '[:upper:]' '[:lower:]' | \
                       sed 's/[^–∞-—èa-z0-9]/-/g; s/-\+/-/g; s/^-//; s/-$//')
                if [ -z "$safe" ]; then
                  anchor="_$COUNT"
                  COUNT=$((COUNT + 1))
                else
                  anchor="$safe"
                fi
                GENERATED_ANCHORS="$GENERATED_ANCHORS
      $anchor"
              done <<< "$HEADINGS"

              if ! echo "$GENERATED_ANCHORS" | grep -Fxq "$ANCHOR"; then
                echo "Broken internal link '$link' in $file (anchor '$ANCHOR' not found in $TARGET_FILE)"
                ERROR_FOUND=true
              else
                echo "Anchor '$ANCHOR' found in $TARGET_FILE"
              fi
            else
              echo "Broken internal link '$link' in $file (target file $TARGET_FILE not found)"
              ERROR_FOUND=true
            fi
          done <<< "$LINKS"
        else
          echo "No internal links in $file"
        fi
      done


      # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ URL (–∏—Å–∫–ª—é—á–∞—è example)
      echo "üîç Checking URLs..."
      if command -v wget >/dev/null; then
        for file in $FILES; do
          # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ [text](http://...) –∏ –≥–æ–ª—ã–µ http://, https://, –∏—Å–∫–ª—é—á–∞—è example
          URLS=$(grep -oP '(?:\[.*?\]\(\Khttp[s]?://[^\s)]+|(?<!\]\()http[s]?://[^\s>]+)' "$file" | grep -v 'example' || true)
          if [ -n "$URLS" ]; then
            echo "üîó Checking URLs in $file: $URLS"
            while IFS= read -r url; do
              if ! wget --spider --timeout=5 --tries=1 "$url" 2>/dev/null; then
                echo "Broken URL: $url in $file"
                ERROR_FOUND=true
              fi
            done <<< "$URLS"
          else
            echo "‚ÑπÔ∏è No URLs (excluding example) in $file"
          fi
        done
      elif command -v curl >/dev/null; then
        for file in $FILES; do
          URLS=$(grep -oP '(?:\[.*?\]\(\Khttp[s]?://[^\s)]+|(?<!\]\()http[s]?://[^\s>]+)' "$file" | grep -v 'example' || true)
          if [ -n "$URLS" ]; then
            echo "üîó Checking URLs in $file: $URLS"
            while IFS= read -r url; do
              if ! curl --silent --head --fail "$url" --connect-timeout 3 --max-time 5 2>/dev/null; then
                echo "Broken URL: $url in $file"
                ERROR_FOUND=true
              fi
            done <<< "$URLS"
          else
            echo "No URLs (excluding example) in $file"
          fi
        done
      else
        echo "Neither wget nor curl found, skipping URL checks"
      fi

      # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      if [ "$ERROR_FOUND" = true ]; then
        echo "Linting failed."
        exit 1
      else
        echo "All checks passed!"
        exit 0
      fi