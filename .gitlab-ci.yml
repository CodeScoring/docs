stages:
  - lint

lint_markdown:
  stage: lint
  script:
    - echo "üîç Starting markdown linting..."
    - echo "Available tools:"
    - which git grep sed tr awk wget curl || echo "Some tools missing"
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö .md —Ñ–∞–π–ª–æ–≤
    - |
      if [ -n "$CI_MERGE_REQUEST_DIFF_BASE_SHA" ]; then
        BASE_REF="$CI_MERGE_REQUEST_DIFF_BASE_SHA"
      else
        echo "Fetching origin/main..."
        git fetch origin main || { echo "‚ùå Failed to fetch origin/main"; exit 1; }
        BASE_REF="origin/main"
      fi

      FILES=$(git diff --name-only "$BASE_REF"...HEAD -- '*.md') || { echo "‚ùå Failed to get changed files"; exit 1; }

      if [ -z "$FILES" ]; then
        echo "‚ÑπÔ∏è No .md files changed."
        exit 0
      fi

      echo "üìÑ Changed files: $FILES"
      ERROR_FOUND=false

      # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ trailing spaces
      echo "üîç Checking trailing spaces..."
      for file in $FILES; do
        if grep -n '[[:blank:]]$' "$file" 2>/dev/null; then
          echo "‚ùå Trailing spaces in $file"
          ERROR_FOUND=true
        fi
      done
      [ "$ERROR_FOUND" = false ] && echo "‚úÖ No trailing spaces."

      # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫ (—Å —É—á–µ—Ç–æ–º –ø—É—Ç–µ–π –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã)
      echo "üîç Checking internal links..."
      for file in $FILES; do
        echo "Processing $file..."
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –≤–∏–¥–∞ [text](#anchor) –∏ [text](/path#anchor)
        LINKS=$(grep -oP '\[.*?\]\(\K(?:#[^\s)]+|/[^\s)]+#[^\s)]+)' "$file" | sed 's/^\(#[^/]\+\|\/[^#]\+#\)/\1/' || true)
        if [ -n "$LINKS" ]; then
          echo "Found links: $LINKS"
          while IFS= read -r link; do
            if [ -n "$link" ]; then
              # –†–∞–∑–¥–µ–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø—É—Ç—å –∏ —è–∫–æ—Ä—å
              if echo "$link" | grep -q '^#'; then
                TARGET_FILE="$file"
                ANCHOR=$(echo "$link" | sed 's/^#//')
              else
                TARGET_FILE=$(echo "$link" | sed 's/#.*$//' | sed 's|^/||; s|\.md$||; s|$|.md|')
                ANCHOR=$(echo "$link" | sed 's|^.*/#||')
                TARGET_FILE="docs/$TARGET_FILE"
              fi
              # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
              if [ -f "$TARGET_FILE" ]; then
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —è–∫–æ—Ä—è –∏–∑ —Ü–µ–ª–µ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
                ANCHORS=$(grep '^##\+' "$TARGET_FILE" | sed 's/^##\+[[:space:]]*//' | tr '[:upper:]' '[:lower:]' | sed 's/[^–∞-—è–ê-–Øa-z0-9]/-/g; s/-\+/-/g; s/^-//; s/-$//' || true)
                ANCHORS_WITH_NUM=$(grep '^##\+' "$TARGET_FILE" | sed 's/^##\+[[:space:]]*//' | tr '[:upper:]' '[:lower:]' | sed 's/[^–∞-—è–ê-–Øa-z0-9]/-/g; s/-\+/-/g; s/^-//; s/-$//' | awk '{print $0; if (NR > 1) print "_" NR}' || true)
                if ! echo "$ANCHORS $ANCHORS_WITH_NUM" | grep -Fx "$ANCHOR" >/dev/null; then
                  echo "‚ùå Broken internal link '$link' in $file (anchor '$ANCHOR' not found in $TARGET_FILE)"
                  ERROR_FOUND=true
                fi
              else
                echo "‚ùå Broken internal link '$link' in $file (target file $TARGET_FILE not found)"
                ERROR_FOUND=true
              fi
            fi
          done <<< "$LINKS"
        else
          echo "‚ÑπÔ∏è No internal links in $file"
        fi
      done

      # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ URL (–≤–∫–ª—é—á–∞—è –≥–æ–ª—ã–µ —Å—Å—ã–ª–∫–∏)
      echo "üîç Checking URLs..."
      if command -v wget >/dev/null; then
        for file in $FILES; do
          # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [text](http://...) –∏ –≥–æ–ª—ã–µ http://, https://
          URLS=$(grep -oP '(?:\[.*?\]\(\Khttp[s]?://[^\s)]+|(?<!\]\()http[s]?://[^\s>]+)' "$file" || true)
          if [ -n "$URLS" ]; then
            echo "üîó Checking URLs in $file: $URLS"
            while IFS= read -r url; do
              if ! wget --spider --timeout=5 --tries=1 "$url" 2>/dev/null; then
                echo "‚ùå Broken URL: $url in $file"
                ERROR_FOUND=true
              fi
            done <<< "$URLS"
          else
            echo "‚ÑπÔ∏è No URLs in $file"
          fi
        done
      elif command -v curl >/dev/null; then
        for file in $FILES; do
          URLS=$(grep -oP '(?:\[.*?\]\(\Khttp[s]?://[^\s)]+|(?<!\]\()http[s]?://[^\s>]+)' "$file" || true)
          if [ -n "$URLS" ]; then
            echo "üîó Checking URLs in $file: $URLS"
            while IFS= read -r url; do
              if ! curl --silent --head --fail "$url" --connect-timeout 3 --max-time 5 2>/dev/null; then
                echo "‚ùå Broken URL: $url in $file"
                ERROR_FOUND=true
              fi
            done <<< "$URLS"
          else
            echo "‚ÑπÔ∏è No URLs in $file"
          fi
        done
      else
        echo "‚ö†Ô∏è Neither wget nor curl found, skipping URL checks"
      fi

      # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      if [ "$ERROR_FOUND" = true ]; then
        echo "‚ùå Linting failed."
        exit 1
      else
        echo "‚úÖ All checks passed!"
        exit 0
      fi