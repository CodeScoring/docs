stages:
  - lint

lint_markdown:
  stage: lint
  script:
    - echo "Starting markdown linting..."
    - echo "Available tools:"
    - which git grep sed tr awk wget curl || echo "‚ùå Some tools missing"
    - |
      if [ -n "$CI_MERGE_REQUEST_DIFF_BASE_SHA" ]; then
        BASE_REF="$CI_MERGE_REQUEST_DIFF_BASE_SHA"
      else
        echo "Fetching origin/main..."
        git fetch origin main || { echo "‚ùå Failed to fetch origin/main"; exit 1; }
        BASE_REF="origin/main"
      fi

      FILES=$(git diff --name-only "$BASE_REF"...HEAD -- '*.md') || { echo "‚ùå Failed to get changed files"; exit 1; }

      if [ -z "$FILES" ]; then
        echo "‚ÑπÔ∏è No .md files changed."
        exit 0
      fi

      echo "üìÑ Changed files: $FILES"
      ERROR_FOUND=false

      # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ trailing spaces
      echo "üîç Checking trailing spaces..."
      for file in $FILES; do
        if grep -n '[[:blank:]]$' "$file" 2>/dev/null; then
          echo "‚ùå Trailing spaces in $file"
          ERROR_FOUND=true
        fi
      done
      [ "$ERROR_FOUND" = false ] && echo "‚úÖ No trailing spaces."

      # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
      echo "üîó Checking internal links..."
      for file in $FILES; do
        echo "Processing $file..."
        LINKS=$(grep -oP '\[.*?\]\(\K(?:#[^\s)]+|/[^\s)]+#[^\s)]+)' "$file" | sed 's/^\(#[^/]\+\|\/[^#]\+#\)/\1/' || true)
        if [ -n "$LINKS" ]; then
          echo "Found links: $LINKS"
          while IFS= read -r link; do
            [ -z "$link" ] && continue

            if echo "$link" | grep -q '^#'; then
              TARGET_FILE="$file"
              ANCHOR="${link#\#}"
            else
              PATH_PART=$(echo "$link" | sed 's/#.*$//; s|^/||; s|/$||')
              TARGET_FILE="docs/${PATH_PART}.md"
              ANCHOR="${link##*#}"
            fi

            if [ -f "$TARGET_FILE" ]; then
              HEADINGS=$(grep -E '^#{1,6} ' "$TARGET_FILE" | sed 's/^#\+ //')
              GENERATED_ANCHORS=""
              COUNT=1
              while IFS= read -r heading; do
                lower=$(echo "$heading" | tr '[:upper:]' '[:lower:]')
                if LC_ALL=C grep -q '[^ -~]' <<< "$lower"; then
                  safe=$(echo "$lower" | iconv -c -t ascii//TRANSLIT | \
                    sed 's/[^a-z0-9]/-/g; s/-\+/-/g; s/^-//; s/-$//')
                else
                  safe=$(echo "$lower" | sed 's/[^a-z0-9]/-/g; s/-\+/-/g; s/^-//; s/-$//')
                fi

                if [ -z "$safe" ]; then
                  anchor="_$COUNT"
                  COUNT=$((COUNT + 1))
                else
                  anchor="$safe"
                fi

                GENERATED_ANCHORS="$GENERATED_ANCHORS
      $anchor"
              done <<< "$HEADINGS"

              if ! echo "$GENERATED_ANCHORS" | grep -Fxq "$ANCHOR"; then
                echo "‚ùå Broken internal link '$link' in $file (anchor '$ANCHOR' not found in $TARGET_FILE)"
                ERROR_FOUND=true
              else
                echo "‚úÖ Anchor '$ANCHOR' found in $TARGET_FILE"
              fi
            else
              echo "‚ùå Broken internal link '$link' in $file (target file $TARGET_FILE not found)"
              ERROR_FOUND=true
            fi
          done <<< "$LINKS"
        else
          echo "‚ÑπÔ∏è No internal links in $file"
        fi
      done

      # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ URL
      echo "üîç Checking URLs..."
      if command -v wget >/dev/null; then
        for file in $FILES; do
          # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ [text](http://...) –∏ –≥–æ–ª—ã–µ http://, https://, –∏—Å–∫–ª—é—á–∞—è example
          URLS=$(grep -oP '(?:\[.*?\]\(\Khttp[s]?://[^\s)]+|(?<!\]\()http[s]?://[^\s>]+)' "$file" | grep -v 'example' || true)
          if [ -n "$URLS" ]; then
            echo "Checking URLs in $file: $URLS"
            while IFS= read -r url; do
              if ! wget --spider --timeout=5 --tries=1 "$url" 2>/dev/null; then
                echo "‚ùå Broken URL: $url in $file"
                ERROR_FOUND=true
              fi
            done <<< "$URLS"
          else
            echo "‚ÑπÔ∏è No URLs (excluding example) in $file"
          fi
        done
      elif command -v curl >/dev/null; then
        for file in $FILES; do
          URLS=$(grep -oP '(?:\[.*?\]\(\Khttp[s]?://[^\s)]+|(?<!\]\()http[s]?://[^\s>]+)' "$file" | grep -v 'example' || true)
          if [ -n "$URLS" ]; then
            echo "Checking URLs in $file: $URLS"
            while IFS= read -r url; do
              if ! curl --silent --head --fail "$url" --connect-timeout 3 --max-time 5 2>/dev/null; then
                echo "‚ùå Broken URL: $url in $file"
                ERROR_FOUND=true
              fi
            done <<< "$URLS"
          else
            echo "‚ÑπÔ∏è No URLs (excluding example) in $file"
          fi
        done
      else
        echo "‚ö†Ô∏è Neither wget nor curl found, skipping URL checks"
      fi

      # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      if [ "$ERROR_FOUND" = true ]; then
        echo "üö´ Linting failed."
        exit 1
      else
        echo "üéâ All checks passed!"
        exit 0
      fi